"""
–®–ê–ì 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
–°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏ FAISS –∏–Ω–¥–µ–∫—Å–∞
–ó–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –û–î–ò–ù –†–ê–ó! –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ cache/
"""

import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer
import faiss
import pickle
from pathlib import Path
from tqdm import tqdm
import time

import config


def load_data():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
    print("=" * 80)
    print("üìÇ –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–•")
    print("=" * 80)

    # –ó–∞–≥—Ä—É–∑–∫–∞ –æ—Ç–∑—ã–≤–æ–≤
    print(f"\n–ó–∞–≥—Ä—É–∑–∫–∞ –æ—Ç–∑—ã–≤–æ–≤ –∏–∑ {config.REVIEWS_FILE}...")
    reviews = pd.read_csv(config.REVIEWS_FILE)

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É —Å —Ç–µ–∫—Å—Ç–æ–º
    if config.TEXT_COLUMN in reviews.columns:
        text_col = config.TEXT_COLUMN
    elif 'review_text' in reviews.columns:
        text_col = 'review_text'
    else:
        text_col = reviews.columns[reviews.dtypes == 'object'][0]
        print(f"‚ö†Ô∏è  –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–ª–æ–Ω–∫—É: {text_col}")

    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –æ—Ç–∑—ã–≤–æ–≤: {len(reviews):,}")

    # –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ–¥–µ–Ω–∏–π
    print(f"\n–ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ–¥–µ–Ω–∏–π –∏–∑ {config.PLACES_FILE}...")
    places = pd.read_csv(config.PLACES_FILE)
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∑–∞–≤–µ–¥–µ–Ω–∏–π: {len(places):,}")

    # –ë–∞–∑–æ–≤–∞—è –æ—á–∏—Å—Ç–∫–∞
    print("\nüßπ –ë–∞–∑–æ–≤–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è...")
    reviews[text_col] = reviews[text_col].fillna('')
    initial_count = len(reviews)
    reviews = reviews[reviews[text_col].str.len() > 10]
    removed = initial_count - len(reviews)

    if removed > 0:
        print(f"   –£–¥–∞–ª–µ–Ω–æ –∫–æ—Ä–æ—Ç–∫–∏—Ö –æ—Ç–∑—ã–≤–æ–≤: {removed:,}")

    print(f"   –§–∏–Ω–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ: {len(reviews):,}")

    return reviews, places, text_col


def create_embeddings(reviews, text_col):
    """–°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è –≤—Å–µ—Ö –æ—Ç–∑—ã–≤–æ–≤"""
    print("\n" + "=" * 80)
    print("üßÆ –°–û–ó–î–ê–ù–ò–ï –≠–ú–ë–ï–î–î–ò–ù–ì–û–í")
    print("=" * 80)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—ç—à–∞
    if config.EMBEDDINGS_CACHE.exists():
        print(f"\n‚ú® –ù–∞–π–¥–µ–Ω –∫—ç—à: {config.EMBEDDINGS_CACHE}")
        response = input("   –ó–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ –∫—ç—à–∞? (y/n): ").lower()

        if response == 'y':
            print("   –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑ –∫—ç—à–∞...")
            with open(config.EMBEDDINGS_CACHE, 'rb') as f:
                embeddings = pickle.load(f)
            print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(embeddings):,} —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏–∑ –∫—ç—à–∞")
            return embeddings

    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
    print(f"\n‚è≥ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏: {config.MODEL_NAME}")
    print("   (–ü–µ—Ä–≤—ã–π —Ä–∞–∑ –∑–∞–π–º–µ—Ç –≤—Ä–µ–º—è –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏)")

    start_time = time.time()
    model = SentenceTransformer(config.MODEL_NAME)
    load_time = time.time() - start_time

    print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∑–∞ {load_time:.1f} —Å–µ–∫")
    print(f"   –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {model.get_sentence_embedding_dimension()}")

    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤
    print(f"\nüìù –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ {len(reviews):,} —Ç–µ–∫—Å—Ç–æ–≤...")
    texts = reviews[text_col].tolist()

    # –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
    print("\n‚è≥ –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤...")
    print(f"   –≠—Ç–æ –∑–∞–π–º–µ—Ç –ø—Ä–∏–º–µ—Ä–Ω–æ {len(texts) * 0.05 / 60:.1f} –º–∏–Ω—É—Ç –Ω–∞ CPU")
    print("   (–º–æ–∂–Ω–æ —Å—Ö–æ–¥–∏—Ç—å –ø–æ–ø–∏—Ç—å –∫–æ—Ñ–µ ‚òï)")

    start_time = time.time()

    embeddings = model.encode(
        texts,
        batch_size=config.BATCH_SIZE,
        show_progress_bar=True,
        convert_to_numpy=True
    )

    elapsed = time.time() - start_time

    print(f"\n‚úÖ –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ —Å–æ–∑–¥–∞–Ω—ã –∑–∞ {elapsed / 60:.1f} –º–∏–Ω—É—Ç")
    print(f"   –†–∞–∑–º–µ—Ä: {embeddings.shape}")
    print(f"   –ü–∞–º—è—Ç—å: {embeddings.nbytes / (1024**2):.1f} MB")

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –∫—ç—à
    print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –∫—ç—à: {config.EMBEDDINGS_CACHE}")
    with open(config.EMBEDDINGS_CACHE, 'wb') as f:
        pickle.dump(embeddings, f)

    print("‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ")

    return embeddings


def build_faiss_index(embeddings):
    """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ FAISS –∏–Ω–¥–µ–∫—Å–∞"""
    print("\n" + "=" * 80)
    print("üèóÔ∏è  –ü–û–°–¢–†–û–ï–ù–ò–ï FAISS –ò–ù–î–ï–ö–°–ê")
    print("=" * 80)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—ç—à–∞
    if config.INDEX_CACHE.exists():
        print(f"\n‚ú® –ù–∞–π–¥–µ–Ω –∫—ç—à: {config.INDEX_CACHE}")
        response = input("   –ó–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ –∫—ç—à–∞? (y/n): ").lower()

        if response == 'y':
            print("   –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑ –∫—ç—à–∞...")
            index = faiss.read_index(str(config.INDEX_CACHE))
            print(f"‚úÖ –ò–Ω–¥–µ–∫—Å –∑–∞–≥—Ä—É–∂–µ–Ω: {index.ntotal:,} –≤–µ–∫—Ç–æ—Ä–æ–≤")
            return index

    print(f"\n‚è≥ –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ –¥–ª—è {len(embeddings):,} –≤–µ–∫—Ç–æ—Ä–æ–≤...")

    dimension = embeddings.shape[1]
    num_vectors = len(embeddings)

    print(f"   –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {dimension}")
    print(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–µ–∫—Ç–æ—Ä–æ–≤: {num_vectors:,}")

    # –í—ã–±–æ—Ä —Ç–∏–ø–∞ –∏–Ω–¥–µ–∫—Å–∞
    if num_vectors < 100000:
        print("\n   –ò—Å–ø–æ–ª—å–∑—É–µ–º IndexFlatIP (—Ç–æ—á–Ω—ã–π –ø–æ–∏—Å–∫)")
        print("   (–î–ª—è <100k –≤–µ–∫—Ç–æ—Ä–æ–≤ - –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ)")
        index = faiss.IndexFlatIP(dimension)
    else:
        print("\n   –ò—Å–ø–æ–ª—å–∑—É–µ–º IndexIVFFlat (–ø—Ä–∏–±–ª–∏–∂–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫)")
        print("   (–î–ª—è >100k –≤–µ–∫—Ç–æ—Ä–æ–≤ - –±—ã—Å—Ç—Ä–µ–µ)")
        nlist = 100
        quantizer = faiss.IndexFlatIP(dimension)
        index = faiss.IndexIVFFlat(quantizer, dimension, nlist)

        print("   –û–±—É—á–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞...")
        index.train(embeddings)

    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞
    print("\n   –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ–∫—Ç–æ—Ä–æ–≤...")
    faiss.normalize_L2(embeddings)

    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–æ–≤
    print("   –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–æ–≤ –≤ –∏–Ω–¥–µ–∫—Å...")
    index.add(embeddings)

    print(f"\n‚úÖ –ò–Ω–¥–µ–∫—Å –ø–æ—Å—Ç—Ä–æ–µ–Ω: {index.ntotal:,} –≤–µ–∫—Ç–æ—Ä–æ–≤")

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –∫—ç—à: {config.INDEX_CACHE}")
    faiss.write_index(index, str(config.INDEX_CACHE))
    print("‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ")

    return index


def save_metadata(reviews, places, text_col):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö"""
    print("\n" + "=" * 80)
    print("üíæ –°–û–•–†–ê–ù–ï–ù–ò–ï –ú–ï–¢–ê–î–ê–ù–ù–´–•")
    print("=" * 80)

    metadata = {
        'reviews': reviews,
        'places': places,
        'text_column': text_col,
        'total_reviews': len(reviews),
        'total_places': len(places),
        'model_name': config.MODEL_NAME
    }

    print(f"\n–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤: {config.METADATA_CACHE}")
    with open(config.METADATA_CACHE, 'wb') as f:
        pickle.dump(metadata, f)

    print("‚úÖ –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã")


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("\n" + "=" * 80)
    print("üöÄ –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• –î–õ–Ø SEMANTIC SEARCH")
    print("=" * 80)
    print("\n–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç:")
    print("  1. –ó–∞–≥—Ä—É–∑–∏—Ç –≤–∞—à–∏ –¥–∞–Ω–Ω—ã–µ")
    print("  2. –°–æ–∑–¥–∞—Å—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –≤—Å–µ—Ö –æ—Ç–∑—ã–≤–æ–≤")
    print("  3. –ü–æ—Å—Ç—Ä–æ–∏—Ç FAISS –∏–Ω–¥–µ–∫—Å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞")
    print("  4. –°–æ—Ö—Ä–∞–Ω–∏—Ç –≤—Å—ë –≤ cache/ –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è")
    print("\n‚è±Ô∏è  –≠—Ç–æ –∑–∞–π–º–µ—Ç 30-60 –º–∏–Ω—É—Ç –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ")
    print("   –ü–æ—Å–ª–µ–¥—É—é—â–∏–µ –∑–∞–ø—É—Å–∫–∏ –±—É–¥—É—Ç –º–≥–Ω–æ–≤–µ–Ω–Ω—ã–º–∏ (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫—ç—à)")
    print("\n" + "=" * 80)

    input("\n–ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è...")

    try:
        # –®–∞–≥ 1: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        reviews, places, text_col = load_data()

        # –®–∞–≥ 2: –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        embeddings = create_embeddings(reviews, text_col)

        # –®–∞–≥ 3: –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞
        index = build_faiss_index(embeddings)

        # –®–∞–≥ 4: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
        save_metadata(reviews, places, text_col)

        # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        print("\n" + "=" * 80)
        print("üéâ –ü–û–î–ì–û–¢–û–í–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê!")
        print("=" * 80)

        print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"   –û—Ç–∑—ã–≤–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(reviews):,}")
        print(f"   –ó–∞–≤–µ–¥–µ–Ω–∏–π –≤ –±–∞–∑–µ: {len(places):,}")
        print(f"   –≠–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Å–æ–∑–¥–∞–Ω–æ: {len(embeddings):,}")
        print(f"   –í–µ–∫—Ç–æ—Ä–æ–≤ –≤ –∏–Ω–¥–µ–∫—Å–µ: {index.ntotal:,}")

        print(f"\nüíæ –§–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {config.CACHE_DIR}")
        print(f"   - {config.EMBEDDINGS_CACHE.name}")
        print(f"   - {config.INDEX_CACHE.name}")
        print(f"   - {config.METADATA_CACHE.name}")

        cache_size = sum(
            f.stat().st_size for f in config.CACHE_DIR.glob('*') if f.is_file()
        ) / (1024**2)
        print(f"\n   –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä –∫—ç—à–∞: {cache_size:.1f} MB")

        print("\n‚úÖ –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å –ø–æ–∏—Å–∫:")
        print("   python step2_search.py")
        print("   –∏–ª–∏")
        print("   streamlit run app.py")

    except FileNotFoundError as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞: –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
        print(f"   {e}")
        print("\n–ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ —Ñ–∞–π–ª—ã –¥–∞–Ω–Ω—ã—Ö –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤:")
        print(f"   {config.DATA_DIR}")

    except Exception as e:
        print(f"\n‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
