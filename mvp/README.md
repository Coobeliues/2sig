# MVP: Семантический поиск заведений 2GIS

Готовый к использованию пайплайн для семантического поиска заведений по описанию.

## Что это делает?

Позволяет искать заведения по естественным запросам на русском и казахском языках:
- "уютное кафе с вкусным кофе"
- "недорогой ресторан с большими порциями"
- "тихое место для работы с wifi"
- "романтическое место для свидания"

**Как это работает:**
1. Отзывы конвертируются в векторные представления (embeddings)
2. Ваш запрос тоже превращается в вектор
3. FAISS находит самые похожие отзывы через косинусное сходство
4. Заведения ранжируются по релевантности

## Системные требования

**Минимум:**
- 8 GB RAM
- 2-4 CPU cores
- 5 GB свободного места на диске

**Время выполнения:**
- Первая подготовка данных: 30-60 минут (один раз)
- Поиск: 50-200 мс на запрос

## Быстрый старт

### 1. Установка зависимостей

```bash
cd /home/keosido/Desktop/nlp_2gis/mvp
pip install -r requirements.txt
```

Будут установлены:
- `pandas` - работа с данными
- `numpy` - численные операции
- `sentence-transformers` - создание эмбеддингов
- `faiss-cpu` - быстрый поиск по векторам
- `tqdm` - прогресс-бары

### 2. Подготовка данных (один раз)

```bash
python step1_prepare.py
```

**Что происходит:**
1. Загружаются CSV файлы с отзывами и заведениями
2. Скачивается модель LaBSE (~500MB, один раз)
3. Создаются embeddings для ~74k отзывов (30-60 мин)
4. Строится FAISS индекс
5. Всё сохраняется в `cache/` для повторного использования

**Выходные файлы:**
```
mvp/cache/
├── embeddings.pkl      # Векторы отзывов (~200 MB)
├── faiss_index.bin     # FAISS индекс (~150 MB)
└── metadata.pkl        # Данные о заведениях и отзывах
```

**Важно:** Этот шаг выполняется только ОДИН раз! При следующих запусках скрипт предложит загрузить из кэша.

### 3. Поиск

**Интерактивный режим:**
```bash
python step2_search.py
# Выберите режим 1 (Интерактивный поиск)
```

Вы сможете вводить свои запросы и видеть результаты в реальном времени.

**Демо режим:**
```bash
python step2_search.py
# Выберите режим 2 (Демо с примерами)
```

Автоматически прогонит несколько примеров запросов.

## Использование в коде

### Базовое использование

```python
from step2_search import SemanticSearch

# Инициализация (загрузка из кэша)
search = SemanticSearch()

# Поиск заведений
results = search.search_places(
    query="уютное кафе с вкусным кофе",
    top_k=10,              # Количество результатов
    min_reviews=3,         # Минимум релевантных отзывов
    aggregation='weighted' # Метод ранжирования
)

# Результаты - pandas DataFrame
for idx, row in results.iterrows():
    print(f"{idx+1}. {row['name']}")
    print(f"   Адрес: {row['address']}")
    print(f"   Рейтинг: {row['rating']:.1f}")
    print(f"   Релевантность: {row['final_score']:.3f}")
    print(f"   Релевантных отзывов: {int(row['review_count'])}\n")
```

### Получение релевантных отзывов

```python
# Получить самые релевантные отзывы для заведения
highlights = search.get_place_highlights(
    place_id=12345,
    query="уютное кафе с вкусным кофе",
    top_k=3
)

for review in highlights:
    print(f"- {review}\n")
```

### Поиск только отзывов

```python
# Найти релевантные отзывы (без группировки по заведениям)
relevant_reviews = search.search_reviews(
    query="большие порции",
    top_k=50
)

print(relevant_reviews[['place_id', 'text_clean', 'similarity_score']])
```

## Настройка параметров

Файл [config.py](config.py) содержит все настройки:

### Пути к данным

```python
DATA_DIR = BASE_DIR.parent / "nlp_analysis"
REVIEWS_FILE = DATA_DIR / "reviews_cleaned_advanced.csv"  # С эмодзи и казахским
PLACES_FILE = DATA_DIR / "places.csv"
```

### Модель

```python
MODEL_NAME = "sentence-transformers/LaBSE"  # Мультиязычная (RU + KZ + EN)

# Альтернативы:
# "DeepPavlov/rubert-base-cased-sentence"  # Только русский, быстрее
# "all-MiniLM-L6-v2"                       # Легкая английская модель
```

### Параметры поиска

```python
DEFAULT_TOP_K = 10           # Количество заведений в результате
DEFAULT_MIN_REVIEWS = 3      # Минимум релевантных отзывов
DEFAULT_AGGREGATION = "weighted"  # Метод ранжирования
BATCH_SIZE = 32              # Размер батча для создания эмбеддингов
```

## Методы агрегации

При поиске заведений используется один из методов для комбинирования scores отзывов:

### 1. **weighted** (рекомендуется)
Учитывает и качество и количество релевантных отзывов:
```python
final_score = avg_similarity * log(review_count + 1)
```
**Плюсы:** Баланс между релевантностью и популярностью
**Когда использовать:** По умолчанию для большинства случаев

### 2. **mean**
Среднее значение similarity score всех релевантных отзывов:
```python
final_score = mean(similarity_scores)
```
**Плюсы:** Высокая точность, меньше шума
**Когда использовать:** Когда важна максимальная релевантность, не популярность

### 3. **max**
Максимальный similarity score среди отзывов:
```python
final_score = max(similarity_scores)
```
**Плюсы:** Находит заведения с хотя бы одним идеальным совпадением
**Когда использовать:** Когда ищете конкретную особенность

## Примеры запросов

### Запросы на русском
```python
search.search_places("уютное кафе с вкусным кофе")
search.search_places("недорогой ресторан с большими порциями")
search.search_places("тихое место для работы с розетками")
search.search_places("романтическое место для свидания")
search.search_places("заведение с живой музыкой")
search.search_places("семейное кафе с детской зоной")
search.search_places("модный бар с коктейлями")
search.search_places("где поесть поздно ночью")
```

### Запросы на казахском
```python
search.search_places("дәмді кофе бар жайлы орын")
search.search_places("арзан мейрамхана үлкен порциялармен")
```

### Смешанные запросы
```python
search.search_places("вкусный кофе және тыныш орын")
```

## Структура результатов

Метод `search_places()` возвращает pandas DataFrame со следующими колонками:

| Колонка | Описание |
|---------|----------|
| `name` | Название заведения |
| `address` | Адрес |
| `category` | Категория (кафе, ресторан и т.д.) |
| `rating` | Рейтинг 2GIS (0-5.0) |
| `final_score` | Финальный score релевантности |
| `avg_score` | Средний similarity score отзывов |
| `review_count` | Количество релевантных отзывов |
| `place_id` | ID заведения |

## Оптимизация производительности

### Кэширование
Все тяжелые вычисления сохраняются в `cache/`:
- **Embeddings** (~200 MB) - создаются один раз
- **FAISS index** (~150 MB) - строится один раз
- **Metadata** - сохраняется один раз

При повторных запусках всё загружается из кэша мгновенно.

### Скорость поиска
- **Первая инициализация:** 3-5 секунд (загрузка модели и индекса)
- **Поиск:** 50-200 мс на запрос
- **Создание эмбеддинга запроса:** ~10 мс
- **FAISS поиск:** ~5 мс для 74k векторов
- **Агрегация и ранжирование:** ~35 мс

### Использование памяти
- **Модель LaBSE:** ~500 MB
- **Embeddings в памяти:** ~200 MB
- **FAISS индекс:** ~150 MB
- **Данные (DataFrames):** ~50 MB
- **Итого:** ~1 GB RAM во время работы

## Устранение проблем

### Ошибка: "Кэш не найден"
```
❌ Кэш не найден: cache/embeddings.pkl
   Сначала запустите: python step1_prepare.py
```
**Решение:** Запустите `python step1_prepare.py` для создания кэша.

### Ошибка: "FileNotFoundError: reviews_cleaned_advanced.csv"
**Решение:** Убедитесь, что файлы данных находятся в:
```
/home/keosido/Desktop/nlp_2gis/nlp_analysis/
├── reviews_cleaned_advanced.csv  (или reviews_full.csv)
└── places.csv
```

### Нет результатов по запросу
```
❌ По вашему запросу ничего не найдено
```
**Возможные причины:**
1. Слишком специфичный запрос
2. Слишком высокий `min_reviews`

**Решение:**
```python
# Уменьшите min_reviews
results = search.search_places(query, min_reviews=1)

# Или измените метод агрегации
results = search.search_places(query, aggregation='max')
```

### Медленное создание эмбеддингов
**На CPU:** 30-60 минут для 74k отзывов - это нормально.

**Ускорение:**
1. Уменьшите `BATCH_SIZE` в config.py если не хватает памяти
2. Используйте GPU версию: `pip install faiss-gpu`

## Следующие шаги

### 1. Улучшение качества
- Попробуйте другие модели в [config.py](config.py)
- Экспериментируйте с методами агрегации
- Настройте `min_reviews` под ваши данные

### 2. Расширение функциональности
- Добавьте фильтры (по категории, рейтингу, району)
- Реализуйте гибридный поиск (semantic + keyword)
- Добавьте переранжирование (cross-encoder)

### 3. Масштабирование
- Используйте quantization для уменьшения размера индекса
- Перейдите на IVF индекс для больших датасетов (>1M)
- Рассмотрите облачное развертывание

## Архитектура

```
┌─────────────────────────────────────────────────────────────┐
│                     STEP 1: ПОДГОТОВКА                       │
│                    (выполняется один раз)                    │
├─────────────────────────────────────────────────────────────┤
│                                                               │
│  reviews_cleaned_advanced.csv                                │
│            ↓                                                  │
│  [SentenceTransformer] ──→ Embeddings (768-dim vectors)      │
│            ↓                                                  │
│  [FAISS] ──→ Индекс для быстрого поиска                      │
│            ↓                                                  │
│  cache/ ← Сохранение всех результатов                        │
│                                                               │
└─────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────┐
│                      STEP 2: ПОИСК                           │
│                  (выполняется многократно)                   │
├─────────────────────────────────────────────────────────────┤
│                                                               │
│  Запрос пользователя                                         │
│            ↓                                                  │
│  [SentenceTransformer] ──→ Query embedding                   │
│            ↓                                                  │
│  [FAISS.search] ──→ Топ-200 релевантных отзывов              │
│            ↓                                                  │
│  [GroupBy place_id] ──→ Агрегация по заведениям             │
│            ↓                                                  │
│  [Ranking] ──→ Топ-K заведений                               │
│            ↓                                                  │
│  Результаты (DataFrame)                                      │
│                                                               │
└─────────────────────────────────────────────────────────────┘
```

## Веб-интерфейс (опционально)

Файл `app.py` содержит Streamlit веб-интерфейс с визуализациями.

**Запуск:**
```bash
streamlit run app.py
```

Откроется в браузере по адресу http://localhost:8501

**Примечание:** Для базового использования достаточно терминала или Jupyter ноутбука.

## Контакты и поддержка

Для вопросов и улучшений создавайте issues или pull requests.
