"""
–ü–ê–†–°–ï–† 2GIS v2 FINAL
–ü–∞—Ä—Å–∏—Ç –æ—Ç–∑—ã–≤—ã –∏–∑ DOM –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –≤—Å–µ—Ö —á–µ—Ä–µ–∑ "–ü–æ–∫–∞–∑–∞—Ç—å –µ—â—ë"
"""
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
import time
import json
import re
from typing import List
from dataclasses import dataclass, asdict
import logging

logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

@dataclass
class Review:
    author: str
    author_reviews_count: int
    rating: float
    text: str
    date: str
    is_verified: bool

@dataclass
class Place:
    name: str
    address: str
    category: str
    rating: float
    reviews_count: int
    phone: str
    url: str
    reviews: List[Review]

class TwoGISParserV2Final:
    """–§–∏–Ω–∞–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è –ø–∞—Ä—Å–µ—Ä–∞ - –ø–∞—Ä—Å–∏—Ç –æ—Ç–∑—ã–≤—ã –∏–∑ DOM"""

    def __init__(self, headless: bool = False):
        self.driver = self._init_driver(headless)
        self.wait = WebDriverWait(self.driver, 15)

    def _init_driver(self, headless: bool):
        options = Options()
        if headless:
            options.add_argument('--headless=new')
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--window-size=1920,1080')

        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=options)
        logger.info("‚úÖ Chrome –∑–∞–ø—É—â–µ–Ω")
        return driver

    def load_all_reviews(self, url: str):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –í–°–ï –æ—Ç–∑—ã–≤—ã –∫–ª–∏–∫–∞—è –Ω–∞ '–ü–æ–∫–∞–∑–∞—Ç—å –µ—â—ë'"""
        logger.info(f"üìÑ –ó–∞–≥—Ä—É–∂–∞—é –≤—Å–µ –æ—Ç–∑—ã–≤—ã —Å: {url}")

        self.driver.get(url)
        time.sleep(5)

        # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ –≤–∫–ª–∞–¥–∫—É –æ—Ç–∑—ã–≤–æ–≤
        reviews_url = url.split('?')[0] + '/tab/reviews'
        logger.info(f"  ‚û°Ô∏è –ü–µ—Ä–µ—Ö–æ–¥ –Ω–∞ –≤–∫–ª–∞–¥–∫—É –æ—Ç–∑—ã–≤–æ–≤...")
        self.driver.get(reviews_url)
        time.sleep(5)

        # –ö–ª–∏–∫–∞–µ–º –Ω–∞ "–ü–æ–∫–∞–∑–∞—Ç—å –µ—â—ë" –ø–æ–∫–∞ –º–æ–∂–µ–º
        logger.info(f"  üìú –ó–∞–≥—Ä—É–∂–∞—é –≤—Å–µ –æ—Ç–∑—ã–≤—ã (–∫–ª–∏–∫)...")
        click_count = 0
        max_clicks = 300

        while click_count < max_clicks:
            # –°–∫—Ä–æ–ª–ª–∏–º –≤–Ω–∏–∑
            self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(0.8)

            # –ò—â–µ–º –∫–Ω–æ–ø–∫—É "–ü–æ–∫–∞–∑–∞—Ç—å –µ—â—ë"
            try:
                button = self.driver.execute_script("""
                    const buttons = document.querySelectorAll('button, div[role="button"], a');
                    for (let btn of buttons) {
                        if (btn.textContent.includes('–ü–æ–∫–∞–∑–∞—Ç—å') ||
                            btn.textContent.includes('–µ—â—ë') ||
                            btn.textContent.includes('–µ—â–µ')) {
                            return btn;
                        }
                    }
                    return null;
                """)

                if button:
                    self.driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", button)
                    time.sleep(0.3)
                    self.driver.execute_script("arguments[0].click();", button)
                    click_count += 1

                    if click_count % 20 == 0:
                        articles_count = len(self.driver.find_elements(By.TAG_NAME, "article"))
                        logger.info(f"    –ö–ª–∏–∫ #{click_count}: –æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç—Å—è {articles_count} –æ—Ç–∑—ã–≤–æ–≤")

                    time.sleep(0.8)
                else:
                    # –ö–Ω–æ–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ - –≤—Å–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã
                    articles_count = len(self.driver.find_elements(By.TAG_NAME, "article"))
                    logger.info(f"  ‚úÖ –ö–Ω–æ–ø–∫–∞ '–ü–æ–∫–∞–∑–∞—Ç—å –µ—â—ë' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
                    logger.info(f"  üíæ –í—Å–µ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç—Å—è {articles_count} –æ—Ç–∑—ã–≤–æ–≤")
                    break

            except Exception as e:
                logger.debug(f"    –û—à–∏–±–∫–∞: {e}")
                break

        logger.info(f"  ‚è±Ô∏è –ñ–¥–µ–º 3 —Å–µ–∫—É–Ω–¥—ã –¥–ª—è –ø–æ–ª–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏...")
        time.sleep(3)

    def parse_reviews_from_dom(self) -> List[Review]:
        """–ü–∞—Ä—Å–∏—Ç –æ—Ç–∑—ã–≤—ã –∏–∑ DOM"""
        reviews = []

        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã article
        articles = self.driver.find_elements(By.TAG_NAME, "article")
        logger.info(f"  üîç –ù–∞–π–¥–µ–Ω–æ {len(articles)} article —ç–ª–µ–º–µ–Ω—Ç–æ–≤")

        for i, article in enumerate(articles):
            try:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç–∑—ã–≤–∞
                text_element = article.find_element(By.CSS_SELECTOR, "[itemprop='reviewBody'], [class*='text'], [class*='Text']")
                text = text_element.text.strip()

                if len(text) < 10:
                    continue

                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–µ–π—Ç–∏–Ω–≥ (–∏–∑ meta —Ç–µ–≥–∞ –∏–ª–∏ aria-label)
                try:
                    rating_el = article.find_element(By.CSS_SELECTOR, "[itemprop='ratingValue'], [aria-label*='–∑–≤–µ–∑–¥']")
                    rating_text = rating_el.get_attribute('content') or rating_el.get_attribute('aria-label')

                    if rating_text:
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–æ –∏–∑ —Ç–µ–∫—Å—Ç–∞
                        rating_match = re.search(r'(\d+)', rating_text)
                        rating = float(rating_match.group(1)) if rating_match else 5.0
                    else:
                        rating = 5.0
                except:
                    rating = 5.0

                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∞–≤—Ç–æ—Ä–∞
                try:
                    author_el = article.find_element(By.CSS_SELECTOR, "[itemprop='author'], [class*='author'], [class*='Author'], [class*='name']")
                    author = author_el.text.strip()
                except:
                    author = "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 2GIS"

                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤ –∞–≤—Ç–æ—Ä–∞
                author_reviews_count = 0
                try:
                    # –ò—â–µ–º —Ç–µ–∫—Å—Ç –≤–∏–¥–∞ "42 –æ—Ç–∑—ã–≤–∞" –∏–ª–∏ "(42)"
                    author_info = article.text
                    count_match = re.search(r'(\d+)\s*–æ—Ç–∑', author_info, re.IGNORECASE)
                    if count_match:
                        author_reviews_count = int(count_match.group(1))
                    else:
                        count_match = re.search(r'\((\d+)\)', author_info)
                        if count_match:
                            author_reviews_count = int(count_match.group(1))
                except:
                    pass

                # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞—Ç—É
                date = ""
                try:
                    date_el = article.find_element(By.CSS_SELECTOR, "[itemprop='datePublished'], [datetime], [class*='date'], [class*='Date']")
                    date_text = date_el.get_attribute('content') or date_el.get_attribute('datetime') or date_el.text
                    if date_text:
                        # –ü–∞—Ä—Å–∏–º –¥–∞—Ç—É (–º–æ–∂–µ—Ç –±—ã—Ç—å ISO —Ñ–æ—Ä–º–∞—Ç –∏–ª–∏ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç)
                        date_match = re.search(r'(\d{4})-(\d{2})-(\d{2})', date_text)
                        if date_match:
                            date = f"{date_match.group(1)}-{date_match.group(2)}-{date_match.group(3)}"
                except:
                    pass

                # –°—Ç–∞—Ç—É—Å –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏ (–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º —á—Ç–æ –≤—Å–µ –≤–∏–¥–∏–º—ã–µ - –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–Ω—ã–µ)
                is_verified = True

                reviews.append(Review(
                    author=author,
                    author_reviews_count=author_reviews_count,
                    rating=rating,
                    text=text[:500],
                    date=date,
                    is_verified=is_verified
                ))

            except Exception as e:
                logger.debug(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ article #{i}: {e}")
                continue

        logger.info(f"  ‚úÖ –°–ø–∞—Ä—Å–µ–Ω–æ {len(reviews)} –æ—Ç–∑—ã–≤–æ–≤ –∏–∑ DOM")
        return reviews

    def get_place_data(self, url: str) -> Place:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –º–µ—Å—Ç–∞"""
        logger.info(f"üìÑ –ü–∞—Ä—Å–∏–º: {url}")

        # –°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∂–∞–µ–º –í–°–ï –æ—Ç–∑—ã–≤—ã
        self.load_all_reviews(url)

        # –ü–æ–ª—É—á–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ initialState
        try:
            initial_state = self.driver.execute_script('return window.initialState')

            profile_data = initial_state.get('data', {}).get('entity', {}).get('profile', {})

            if not profile_data:
                logger.error("‚ùå –î–∞–Ω–Ω—ã–µ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                return None

            org_data = list(profile_data.values())[0]['data']

            name = org_data.get('name', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
            address_obj = org_data.get('address', {})
            address = address_obj.get('name', '–ù–µ —É–∫–∞–∑–∞–Ω')

            rubrics = org_data.get('rubrics', [])
            category = rubrics[0].get('name', '–ù–µ —É–∫–∞–∑–∞–Ω–∞') if rubrics else '–ù–µ —É–∫–∞–∑–∞–Ω–∞'

            reviews_obj = org_data.get('reviews', {})
            rating = reviews_obj.get('general_rating', 0.0)
            reviews_count = reviews_obj.get('general_review_count', 0)

            phone = "–ù–µ —É–∫–∞–∑–∞–Ω"
            contact_groups = org_data.get('contact_groups', [])
            for group in contact_groups:
                contacts = group.get('contacts', [])
                for contact in contacts:
                    if contact.get('type') == 'phone':
                        phone = contact.get('text', phone)
                        break

            logger.info(f"‚úì {name}")
            logger.info(f"  –†–µ–π—Ç–∏–Ω–≥: {rating}, –û—Ç–∑—ã–≤–æ–≤: {reviews_count}")

            # –ü–∞—Ä—Å–∏–º –æ—Ç–∑—ã–≤—ã –∏–∑ DOM
            reviews = self.parse_reviews_from_dom()

            return Place(
                name=name,
                address=address,
                category=category,
                rating=rating,
                reviews_count=reviews_count,
                phone=phone,
                url=url,
                reviews=reviews
            )

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            import traceback
            traceback.print_exc()
            return None

    def save_to_json(self, places: List[Place], filename: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ JSON"""
        data = [asdict(place) for place in places]

        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        logger.info(f"\nüíæ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filename}")

    def close(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ –±—Ä–∞—É–∑–µ—Ä–∞"""
        self.driver.quit()
        logger.info("üëã –ì–æ—Ç–æ–≤–æ!")

# ===================================================================
# –ó–ê–ü–£–°–ö
# ===================================================================
if __name__ == "__main__":
    import sys
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

    print("=" * 70)
    print("üöÄ –ü–ê–†–°–ï–† 2GIS v2 FINAL - –ü–∞—Ä—Å–∏–Ω–≥ –∏–∑ DOM")
    print("=" * 70)
    print()

    scraper = TwoGISParserV2Final(headless=False)

    try:
        url = "https://2gis.kz/almaty/firm/70000001057770550"

        place = scraper.get_place_data(url)

        if place:
            print("\n" + "=" * 70)
            print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´")
            print("=" * 70)
            print(f"\n{place.name}")
            print(f" üìç {place.address}")
            print(f" üìÇ {place.category}")
            print(f" ‚≠ê {place.rating} ({place.reviews_count} –æ—Ç–∑—ã–≤–æ–≤)")
            print(f" üìû {place.phone}")
            print(f" üí¨ –°–æ–±—Ä–∞–Ω–æ –æ—Ç–∑—ã–≤–æ–≤: {len(place.reviews)}")

            if place.reviews:
                print(f"\n üìù –ü—Ä–∏–º–µ—Ä—ã –æ—Ç–∑—ã–≤–æ–≤:")
                for j, review in enumerate(place.reviews[:5], 1):
                    count_str = f" ({review.author_reviews_count} –æ—Ç–∑.)" if review.author_reviews_count > 0 else ""
                    date_str = f" [{review.date}]" if review.date else ""
                    status_str = "" if review.is_verified else " [–ù–ï –ü–û–î–¢–í–ï–†–ñ–î–ï–ù]"
                    print(f" {j}. {review.author}{count_str} ‚≠ê{review.rating}{date_str}{status_str}")
                    print(f"    \"{review.text[:80]}...\"")

            scraper.save_to_json([place], "2gis_result_v2_final.json")

            print("\n" + "=" * 70)
            print("‚úÖ –ì–û–¢–û–í–û! –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–∞–π–ª: 2gis_result_v2_final.json")
            print("=" * 70)
        else:
            print("\n‚ùå –î–∞–Ω–Ω—ã–µ –Ω–µ —Å–æ–±—Ä–∞–Ω—ã")

    except Exception as e:
        print(f"\n‚ùå –û–®–ò–ë–ö–ê: {e}")
        import traceback
        traceback.print_exc()

    finally:
        scraper.close()
