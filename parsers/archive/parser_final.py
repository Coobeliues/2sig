"""
–ü–ê–†–°–ï–† 2GIS - –§–ò–ù–ê–õ–¨–ù–ê–Ø –í–ï–†–°–ò–Ø
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç window.initialState –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–µ—Ä–≤—ã—Ö 50 –æ—Ç–∑—ã–≤–æ–≤
–í—Å–µ –ø–æ–ª—è –ø–∞—Ä—Å—è—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ: author, author_reviews_count, rating, text, date, is_verified
"""
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
import time
import json
from typing import List
from dataclasses import dataclass, asdict
import logging

logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

@dataclass
class Review:
    author: str
    author_reviews_count: int
    rating: float
    text: str
    date: str
    is_verified: bool

@dataclass
class Place:
    name: str
    address: str
    category: str
    rating: float
    reviews_count: int
    phone: str
    url: str
    reviews: List[Review]

class TwoGISParser:
    """–ü–∞—Ä—Å–µ—Ä 2GIS —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º –≤—Å–µ—Ö –ø–æ–ª–µ–π"""

    def __init__(self, headless: bool = False):
        self.driver = self._init_driver(headless)
        self.wait = WebDriverWait(self.driver, 15)

    def _init_driver(self, headless: bool):
        options = Options()
        if headless:
            options.add_argument('--headless=new')
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--window-size=1920,1080')

        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=options)
        logger.info("‚úÖ Chrome –∑–∞–ø—É—â–µ–Ω")
        return driver

    def get_place_data(self, url: str) -> Place:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ window.initialState"""
        logger.info(f"üìÑ –ü–∞—Ä—Å–∏–º: {url}")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å –æ—Ç–∑—ã–≤–∞–º–∏
        reviews_url = url.split('?')[0] + '/tab/reviews'
        self.driver.get(reviews_url)
        time.sleep(5)

        try:
            initial_state = self.driver.execute_script('return window.initialState')

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            with open('initial_state.json', 'w', encoding='utf-8') as f:
                json.dump(initial_state, f, ensure_ascii=False, indent=2)
            logger.info("üíæ initialState —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ initial_state.json")

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏
            profile_data = initial_state.get('data', {}).get('entity', {}).get('profile', {})

            if not profile_data:
                logger.error("‚ùå –î–∞–Ω–Ω—ã–µ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ initialState")
                return None

            # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –æ–±—ä–µ–∫—Ç
            org_data = list(profile_data.values())[0]['data']

            # –û—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            name = org_data.get('name', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
            address_obj = org_data.get('address', {})
            address = address_obj.get('name', '–ù–µ —É–∫–∞–∑–∞–Ω')

            # –ö–∞—Ç–µ–≥–æ—Ä–∏—è
            rubrics = org_data.get('rubrics', [])
            category = rubrics[0].get('name', '–ù–µ —É–∫–∞–∑–∞–Ω–∞') if rubrics else '–ù–µ —É–∫–∞–∑–∞–Ω–∞'

            # –†–µ–π—Ç–∏–Ω–≥ –∏ –æ—Ç–∑—ã–≤—ã
            reviews_obj = org_data.get('reviews', {})
            rating = reviews_obj.get('general_rating', 0.0)
            reviews_count = reviews_obj.get('general_review_count', 0)

            # –¢–µ–ª–µ—Ñ–æ–Ω
            phone = "–ù–µ —É–∫–∞–∑–∞–Ω"
            contact_groups = org_data.get('contact_groups', [])
            for group in contact_groups:
                contacts = group.get('contacts', [])
                for contact in contacts:
                    if contact.get('type') == 'phone':
                        phone = contact.get('text', phone)
                        break

            logger.info(f"‚úì {name}")
            logger.info(f"  –†–µ–π—Ç–∏–Ω–≥: {rating}, –û—Ç–∑—ã–≤–æ–≤: {reviews_count}")

            # –°–æ–±–∏—Ä–∞–µ–º –æ—Ç–∑—ã–≤—ã
            reviews = self.get_reviews(initial_state)

            return Place(
                name=name,
                address=address,
                category=category,
                rating=rating,
                reviews_count=reviews_count,
                phone=phone,
                url=url,
                reviews=reviews
            )

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è initialState: {e}")
            import traceback
            traceback.print_exc()
            return None

    def get_reviews(self, initial_state: dict) -> List[Review]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ—Ç–∑—ã–≤–æ–≤ –∏–∑ initialState"""
        reviews = []

        try:
            # –ò—â–µ–º –æ—Ç–∑—ã–≤—ã –≤ initialState
            # –°—Ç—Ä—É–∫—Ç—É—Ä–∞: initialState.data.review[id] = {data: {...}}
            reviews_data = initial_state.get('data', {}).get('review', {})

            if not reviews_data:
                logger.info("  ‚ÑπÔ∏è –û—Ç–∑—ã–≤—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ initialState")
                return []

            logger.info(f"  üîç –ù–∞–π–¥–µ–Ω–æ {len(reviews_data)} –æ—Ç–∑—ã–≤–æ–≤ –≤ initialState")

            for review_id, review_obj in reviews_data.items():
                try:
                    review_data = review_obj.get('data', {})

                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ—Ç–∑—ã–≤–∞
                    text = review_data.get('text', '')
                    if len(text) < 30:
                        continue

                    rating = review_data.get('rating', 5.0)

                    # –î–∞—Ç–∞: –∏—Å–ø–æ–ª—å–∑—É–µ–º date_edited –µ—Å–ª–∏ –µ—Å—Ç—å (–¥–ª—è –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤),
                    # –∏–Ω–∞—á–µ date_created (–¥–ª—è –Ω–æ–≤—ã—Ö –æ—Ç–∑—ã–≤–æ–≤)
                    date_edited = review_data.get('date_edited', '')
                    date_created = review_data.get('date_created', '')
                    date_str = date_edited if date_edited else date_created
                    date = date_str.split('T')[0] if 'T' in date_str else ''

                    # –î–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                    user = review_data.get('user', {})
                    author = user.get('name', '–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 2GIS')
                    author_reviews_count = user.get('reviews_count', 0)

                    # –°—Ç–∞—Ç—É—Å –º–æ–¥–µ—Ä–∞—Ü–∏–∏ (is_hidden = True –æ–∑–Ω–∞—á–∞–µ—Ç —Å–∫—Ä—ã—Ç/–Ω–∞ –º–æ–¥–µ—Ä–∞—Ü–∏–∏)
                    is_hidden = review_data.get('is_hidden', False)
                    is_verified = not is_hidden  # –ò–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º: True = –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω, False = —Å–∫—Ä—ã—Ç

                    reviews.append(Review(
                        author=author,
                        author_reviews_count=author_reviews_count,
                        rating=rating,
                        text=text[:500],
                        date=date,
                        is_verified=is_verified
                    ))

                except Exception as e:
                    logger.debug(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—Ç–∑—ã–≤–∞ {review_id}: {e}")
                    continue

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å—Ç–∞—Ç—É—Å–∞–º
            verified_count = sum(1 for r in reviews if r.is_verified)
            unverified_count = len(reviews) - verified_count

            logger.info(f"  ‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(reviews)} –æ—Ç–∑—ã–≤–æ–≤ (–ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–æ: {verified_count}, –Ω–∞ –º–æ–¥–µ—Ä–∞—Ü–∏–∏: {unverified_count})")
            return reviews

        except Exception as e:
            logger.error(f"  ‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –æ—Ç–∑—ã–≤–æ–≤: {e}")
            import traceback
            traceback.print_exc()
            return []

    def save_to_json(self, places: List[Place], filename: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ JSON"""
        data = [asdict(place) for place in places]

        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        logger.info(f"\nüíæ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filename}")

    def close(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ –±—Ä–∞—É–∑–µ—Ä–∞"""
        self.driver.quit()
        logger.info("üëã –ì–æ—Ç–æ–≤–æ!")

# ===================================================================
# –ó–ê–ü–£–°–ö
# ===================================================================
if __name__ == "__main__":
    import sys
    import io
    # –§–∏–∫—Å –∫–æ–¥–∏—Ä–æ–≤–∫–∏ –¥–ª—è Windows
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

    print("=" * 70)
    print("üöÄ –ü–ê–†–°–ï–† 2GIS - –§–∏–Ω–∞–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è")
    print("=" * 70)
    print()

    scraper = TwoGISParser(headless=False)

    try:
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ –æ–¥–Ω–æ–º URL
        url = "https://2gis.kz/almaty/firm/70000001057770550"

        place = scraper.get_place_data(url)

        if place:
            print("\n" + "=" * 70)
            print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´")
            print("=" * 70)
            print(f"\n{place.name}")
            print(f" üìç {place.address}")
            print(f" üìÇ {place.category}")
            print(f" ‚≠ê {place.rating} ({place.reviews_count} –æ—Ç–∑—ã–≤–æ–≤)")
            print(f" üìû {place.phone}")
            print(f" üí¨ –°–æ–±—Ä–∞–Ω–æ –æ—Ç–∑—ã–≤–æ–≤: {len(place.reviews)}")

            if place.reviews:
                print(f"\n üìù –ü—Ä–∏–º–µ—Ä—ã –æ—Ç–∑—ã–≤–æ–≤:")
                for j, review in enumerate(place.reviews[:10], 1):
                    count_str = f" ({review.author_reviews_count} –æ—Ç–∑.)" if review.author_reviews_count > 0 else ""
                    date_str = f" [{review.date}]" if review.date else ""
                    status_str = "" if review.is_verified else " [–ù–ï –ü–û–î–¢–í–ï–†–ñ–î–ï–ù]"
                    print(f" {j}. {review.author}{count_str} ‚≠ê{review.rating}{date_str}{status_str}")
                    print(f"    \"{review.text[:80]}...\"")

            scraper.save_to_json([place], "2gis_result_final.json")

            print("\n" + "=" * 70)
            print("‚úÖ –ì–û–¢–û–í–û! –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–∞–π–ª: 2gis_result_final.json")
            print("=" * 70)
        else:
            print("\n‚ùå –î–∞–Ω–Ω—ã–µ –Ω–µ —Å–æ–±—Ä–∞–Ω—ã")

    except Exception as e:
        print(f"\n‚ùå –û–®–ò–ë–ö–ê: {e}")
        import traceback
        traceback.print_exc()

    finally:
        scraper.close()
