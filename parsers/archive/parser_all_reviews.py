"""
–ü–ê–†–°–ï–† 2GIS - –í–°–ï –û–¢–ó–´–í–´
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç selenium-wire –¥–ª—è –ø–µ—Ä–µ—Ö–≤–∞—Ç–∞ API –∑–∞–ø—Ä–æ—Å–æ–≤
–ü–æ–∑–≤–æ–ª—è–µ—Ç –ø–æ–ª—É—á–∏—Ç—å –í–°–ï –æ—Ç–∑—ã–≤—ã, –∞ –Ω–µ —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 50
"""
from seleniumwire import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
import time
import json
from typing import List, Dict
from dataclasses import dataclass, asdict
import logging

logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

@dataclass
class Review:
    author: str
    author_reviews_count: int
    rating: float
    text: str
    date: str
    is_verified: bool

@dataclass
class Place:
    name: str
    address: str
    category: str
    rating: float
    reviews_count: int
    phone: str
    url: str
    reviews: List[Review]

class TwoGISParserAllReviews:
    """–ü–∞—Ä—Å–µ—Ä —Å –ø–µ—Ä–µ—Ö–≤–∞—Ç–æ–º API –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –í–°–ï–• –æ—Ç–∑—ã–≤–æ–≤"""

    def __init__(self, headless: bool = False):
        self.all_reviews = {}  # –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –≤—Å–µ—Ö —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤
        self.driver = self._init_driver(headless)

    def _init_driver(self, headless: bool):
        options = Options()
        if headless:
            options.add_argument('--headless=new')
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--window-size=1920,1080')

        # –û—Ç–∫–ª—é—á–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
        prefs = {"profile.managed_default_content_settings.images": 2}
        options.add_experimental_option("prefs", prefs)

        service = Service(ChromeDriverManager().install())

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º selenium-wire –¥–ª—è –ø–µ—Ä–µ—Ö–≤–∞—Ç–∞ –∑–∞–ø—Ä–æ—Å–æ–≤
        seleniumwire_options = {
            'disable_encoding': True  # –î–ª—è –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–æ–≤
        }

        driver = webdriver.Chrome(
            service=service,
            options=options,
            seleniumwire_options=seleniumwire_options
        )

        logger.info("‚úÖ Chrome –∑–∞–ø—É—â–µ–Ω —Å –ø–µ—Ä–µ—Ö–≤–∞—Ç–æ–º —Å–µ—Ç–∏")
        return driver

    def _process_network_requests(self):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–µ—Ç–µ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –æ—Ç–∑—ã–≤—ã –∏–∑ API –æ—Ç–≤–µ—Ç–æ–≤"""
        for request in self.driver.requests:
            # –ò—â–µ–º –∑–∞–ø—Ä–æ—Å—ã –∫ API —Å –æ—Ç–∑—ã–≤–∞–º–∏
            if request.response and 'reviews' in request.url:
                try:
                    # –î–µ–∫–æ–¥–∏—Ä—É–µ–º —Ç–µ–ª–æ –æ—Ç–≤–µ—Ç–∞
                    body = request.response.body.decode('utf-8')
                    data = json.loads(body)

                    # –ò—â–µ–º –æ—Ç–∑—ã–≤—ã –≤ —Ä–∞–∑–Ω—ã—Ö –≤–æ–∑–º–æ–∂–Ω—ã—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä–∞—Ö
                    items = None
                    if 'items' in data:
                        items = data['items']
                    elif 'result' in data and isinstance(data['result'], dict) and 'items' in data['result']:
                        items = data['result']['items']
                    elif 'data' in data and 'review' in data['data']:
                        items = data['data']['review'].values()

                    if items:
                        for item in items:
                            # –ò–∑–≤–ª–µ–∫–∞–µ–º ID –æ—Ç–∑—ã–≤–∞
                            if isinstance(item, dict):
                                review_id = item.get('id') or item.get('local_item_id')
                                if review_id and review_id not in self.all_reviews:
                                    self.all_reviews[review_id] = item

                except Exception as e:
                    logger.debug(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞ {request.url}: {e}")
                    continue

    def load_all_reviews(self, url: str):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –í–°–ï –æ—Ç–∑—ã–≤—ã —á–µ—Ä–µ–∑ —Å–∫—Ä–æ–ª–ª–∏–Ω–≥ –∏ –∫–ª–∏–∫–∏"""
        logger.info(f"üìÑ –ó–∞–≥—Ä—É–∂–∞—é –≤—Å–µ –æ—Ç–∑—ã–≤—ã —Å: {url}")

        # –°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∂–∞–µ–º –æ—Å–Ω–æ–≤–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
        self.driver.get(url)
        time.sleep(5)

        # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ –≤–∫–ª–∞–¥–∫—É –æ—Ç–∑—ã–≤–æ–≤
        reviews_url = url.split('?')[0] + '/tab/reviews'
        logger.info(f"  ‚û°Ô∏è –ü–µ—Ä–µ—Ö–æ–¥ –Ω–∞ –≤–∫–ª–∞–¥–∫—É –æ—Ç–∑—ã–≤–æ–≤...")
        self.driver.get(reviews_url)
        time.sleep(8)  # –£–≤–µ–ª–∏—á–∏–ª–∏ –æ–∂–∏–¥–∞–Ω–∏–µ

        logger.info(f"  üìú –ó–∞–≥—Ä—É–∂–∞—é –≤—Å–µ –æ—Ç–∑—ã–≤—ã (–∫–ª–∏–∫ + –ø–µ—Ä–µ—Ö–≤–∞—Ç API)...")
        click_count = 0
        max_clicks = 300
        last_count = 0
        no_change_count = 0

        while click_count < max_clicks:
            # –°–∫—Ä–æ–ª–ª–∏–º –≤–Ω–∏–∑
            self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(0.5)

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–µ—Ç–µ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã
            self._process_network_requests()

            # –ò—â–µ–º –∫–Ω–æ–ø–∫—É "–ü–æ–∫–∞–∑–∞—Ç—å –µ—â—ë"
            try:
                button = self.driver.execute_script("""
                    const buttons = document.querySelectorAll('button, div[role="button"], a');
                    for (let btn of buttons) {
                        if (btn.textContent.includes('–ü–æ–∫–∞–∑–∞—Ç—å') ||
                            btn.textContent.includes('–µ—â—ë') ||
                            btn.textContent.includes('–µ—â–µ')) {
                            return btn;
                        }
                    }
                    return null;
                """)

                if button:
                    self.driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", button)
                    time.sleep(0.3)
                    self.driver.execute_script("arguments[0].click();", button)
                    click_count += 1

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                    current_count = len(self.all_reviews)

                    if click_count % 20 == 0:
                        logger.info(f"    –ö–ª–∏–∫ #{click_count}: —Å–æ–±—Ä–∞–Ω–æ {current_count} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤")

                    # –ï—Å–ª–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ –º–µ–Ω—è–µ—Ç—Å—è - –≤–æ–∑–º–æ–∂–Ω–æ –≤—Å–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã
                    if current_count == last_count:
                        no_change_count += 1
                        if no_change_count >= 10:
                            logger.info(f"  ‚úÖ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤ –Ω–µ –º–µ–Ω—è–µ—Ç—Å—è - –≤—Å–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!")
                            break
                    else:
                        no_change_count = 0

                    last_count = current_count
                    time.sleep(0.5)
                else:
                    # –ö–Ω–æ–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞
                    logger.info(f"  ‚úÖ –ö–Ω–æ–ø–∫–∞ '–ü–æ–∫–∞–∑–∞—Ç—å –µ—â—ë' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
                    break

            except Exception as e:
                logger.debug(f"    –û—à–∏–±–∫–∞: {e}")
                break

        # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        self._process_network_requests()
        logger.info(f"  üíæ –í—Å–µ–≥–æ —Å–æ–±—Ä–∞–Ω–æ {len(self.all_reviews)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤")

    def parse_reviews(self) -> List[Review]:
        """–ü–∞—Ä—Å–∏—Ç —Å–æ–±—Ä–∞–Ω–Ω—ã–µ –æ—Ç–∑—ã–≤—ã"""
        reviews = []

        logger.info(f"  üîç –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é {len(self.all_reviews)} –æ—Ç–∑—ã–≤–æ–≤...")

        for review_id, review_data in self.all_reviews.items():
            try:
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–∞–∑–Ω—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö
                if 'data' in review_data:
                    review_data = review_data['data']

                # –¢–µ–∫—Å—Ç –æ—Ç–∑—ã–≤–∞
                text = review_data.get('text', '')
                if len(text) < 30:
                    continue

                # –†–µ–π—Ç–∏–Ω–≥
                rating = review_data.get('rating', 5.0)

                # –î–∞—Ç–∞
                date_edited = review_data.get('date_edited', '')
                date_created = review_data.get('date_created', '')
                date_str = date_edited if date_edited else date_created
                date = date_str.split('T')[0] if 'T' in date_str else ''

                # –ê–≤—Ç–æ—Ä
                user = review_data.get('user', {})
                author = user.get('name', '–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å 2GIS')
                author_reviews_count = user.get('reviews_count', 0)

                # –°—Ç–∞—Ç—É—Å
                is_hidden = review_data.get('is_hidden', False)
                is_verified = not is_hidden

                reviews.append(Review(
                    author=author,
                    author_reviews_count=author_reviews_count,
                    rating=rating,
                    text=text[:500],
                    date=date,
                    is_verified=is_verified
                ))

            except Exception as e:
                logger.debug(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—Ç–∑—ã–≤–∞ {review_id}: {e}")
                continue

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        verified_count = sum(1 for r in reviews if r.is_verified)
        unverified_count = len(reviews) - verified_count

        logger.info(f"  ‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(reviews)} –æ—Ç–∑—ã–≤–æ–≤ (–ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–æ: {verified_count}, –Ω–∞ –º–æ–¥–µ—Ä–∞—Ü–∏–∏: {unverified_count})")
        return reviews

    def get_place_data(self, url: str) -> Place:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –º–µ—Å—Ç–∞"""
        logger.info(f"üìÑ –ü–∞—Ä—Å–∏–º: {url}")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –æ—Ç–∑—ã–≤—ã
        self.load_all_reviews(url)

        # –ü–æ–ª—É—á–∞–µ–º –±–∞–∑–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ initialState
        try:
            initial_state = self.driver.execute_script('return window.initialState')

            if not initial_state:
                logger.error("‚ùå window.initialState –ø—É—Å—Ç–æ–π –∏–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω")
                return None

            profile_data = initial_state.get('data', {}).get('entity', {}).get('profile', {})

            if not profile_data:
                logger.error("‚ùå –î–∞–Ω–Ω—ã–µ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                return None

            org_data = list(profile_data.values())[0]['data']

            name = org_data.get('name', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
            address_obj = org_data.get('address', {})
            address = address_obj.get('name', '–ù–µ —É–∫–∞–∑–∞–Ω')

            rubrics = org_data.get('rubrics', [])
            category = rubrics[0].get('name', '–ù–µ —É–∫–∞–∑–∞–Ω–∞') if rubrics else '–ù–µ —É–∫–∞–∑–∞–Ω–∞'

            reviews_obj = org_data.get('reviews', {})
            rating = reviews_obj.get('general_rating', 0.0)
            reviews_count = reviews_obj.get('general_review_count', 0)

            phone = "–ù–µ —É–∫–∞–∑–∞–Ω"
            contact_groups = org_data.get('contact_groups', [])
            for group in contact_groups:
                contacts = group.get('contacts', [])
                for contact in contacts:
                    if contact.get('type') == 'phone':
                        phone = contact.get('text', phone)
                        break

            logger.info(f"‚úì {name}")
            logger.info(f"  –†–µ–π—Ç–∏–Ω–≥: {rating}, –û—Ç–∑—ã–≤–æ–≤ –≤—Å–µ–≥–æ: {reviews_count}")

            # –ü–∞—Ä—Å–∏–º —Å–æ–±—Ä–∞–Ω–Ω—ã–µ –æ—Ç–∑—ã–≤—ã
            reviews = self.parse_reviews()

            return Place(
                name=name,
                address=address,
                category=category,
                rating=rating,
                reviews_count=reviews_count,
                phone=phone,
                url=url,
                reviews=reviews
            )

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            import traceback
            traceback.print_exc()
            return None

    def save_to_json(self, places: List[Place], filename: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ JSON"""
        data = [asdict(place) for place in places]

        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        logger.info(f"\nüíæ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filename}")

    def close(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ –±—Ä–∞—É–∑–µ—Ä–∞"""
        self.driver.quit()
        logger.info("üëã –ì–æ—Ç–æ–≤–æ!")

# ===================================================================
# –ó–ê–ü–£–°–ö
# ===================================================================
if __name__ == "__main__":
    import sys
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

    print("=" * 70)
    print("üöÄ –ü–ê–†–°–ï–† 2GIS - –í–°–ï –û–¢–ó–´–í–´ (—Å –ø–µ—Ä–µ—Ö–≤–∞—Ç–æ–º API)")
    print("=" * 70)
    print()

    scraper = TwoGISParserAllReviews(headless=False)

    try:
        url = "https://2gis.kz/almaty/firm/70000001057770550"

        place = scraper.get_place_data(url)

        if place:
            print("\n" + "=" * 70)
            print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´")
            print("=" * 70)
            print(f"\n{place.name}")
            print(f" üìç {place.address}")
            print(f" üìÇ {place.category}")
            print(f" ‚≠ê {place.rating} ({place.reviews_count} –æ—Ç–∑—ã–≤–æ–≤)")
            print(f" üìû {place.phone}")
            print(f" üí¨ –°–æ–±—Ä–∞–Ω–æ –æ—Ç–∑—ã–≤–æ–≤: {len(place.reviews)}")

            if place.reviews:
                print(f"\n üìù –ü—Ä–∏–º–µ—Ä—ã –æ—Ç–∑—ã–≤–æ–≤:")
                for j, review in enumerate(place.reviews[:10], 1):
                    count_str = f" ({review.author_reviews_count} –æ—Ç–∑.)" if review.author_reviews_count > 0 else ""
                    date_str = f" [{review.date}]" if review.date else ""
                    status_str = "" if review.is_verified else " [–ù–ï –ü–û–î–¢–í–ï–†–ñ–î–ï–ù]"
                    print(f" {j}. {review.author}{count_str} ‚≠ê{review.rating}{date_str}{status_str}")
                    print(f"    \"{review.text[:80]}...\"")

            scraper.save_to_json([place], "2gis_all_reviews.json")

            print("\n" + "=" * 70)
            print(f"‚úÖ –ì–û–¢–û–í–û! –°–æ–±—Ä–∞–Ω–æ {len(place.reviews)} –æ—Ç–∑—ã–≤–æ–≤ –∏–∑ {place.reviews_count}")
            print("‚úÖ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–∞–π–ª: 2gis_all_reviews.json")
            print("=" * 70)
        else:
            print("\n‚ùå –î–∞–Ω–Ω—ã–µ –Ω–µ —Å–æ–±—Ä–∞–Ω—ã")

    except Exception as e:
        print(f"\n‚ùå –û–®–ò–ë–ö–ê: {e}")
        import traceback
        traceback.print_exc()

    finally:
        scraper.close()
